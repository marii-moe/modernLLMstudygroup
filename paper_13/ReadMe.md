# Chain of Papers Symposium

This week is a mini- Chain of Thought symposium with multiple 10 minute presentations on XoT papers:
* [*Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*](https://arxiv.org/abs/2201.11903)
* [*Self-Consistency Improves Chain of Thought Reasoning in Language Models*](https://arxiv.org/abs/2203.11171)
* [*Least-to-Most Prompting Enables Complex Reasoning in Large Language Models*](https://arxiv.org/abs/2205.10625)
* [*Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks*](https://arxiv.org/abs/2211.12588)
* [*Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models*](https://arxiv.org/abs/2305.04091)
* [*Tree of Thoughts: Deliberate Problem Solving with Large Language Models*](https://arxiv.org/abs/2305.10601) Plus [ToT via prompting](https://github.com/dave1010/tree-of-thought-prompting)
* [*Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding*](https://arxiv.org/abs/2307.15337)
* [*From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting*](https://arxiv.org/abs/2309.04269)
* [*Chain-of-Verification Reduces Hallucination in Large Language Models*](https://arxiv.org/abs/2309.11495)

Further Reading:
* [*Show Your Work: Scratchpads for Intermediate Computation with Language Models*](https://arxiv.org/abs/2112.00114)
* [*Language Model Cascades*](https://arxiv.org/abs/2207.10342)
* [*Faithful Chain-of-Thought Reasoning*](https://arxiv.org/abs/2301.13379)
* [*Active Prompting with Chain-of-Thought for Large Language Models*](https://arxiv.org/abs/2302.12246)
* [*Self-Refine: Iterative Refinement with Self-Feedback*](https://arxiv.org/abs/2303.17651)
* [*Tab-CoT: Zero-shot Tabular Chain of Thought*](https://arxiv.org/abs/2305.17812)
* [*Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method*](https://arxiv.org/abs/2305.13412)
* [*Reasoning Implicit Sentiment with Chain-of-Thought Prompting*](https://arxiv.org/abs/2305.11255)
* [*Deductive Verification of Chain-of-Thought Reasoning*](https://arxiv.org/abs/2306.03872)
* [*Graph of Thoughts: Solving Elaborate Problems with Large Language Models*](https://arxiv.org/abs/2308.09687)
* [*Promptbreeder: Self-Referential Self-Improvement via Prompt Evolution*](https://arxiv.org/abs/2309.16797)
* [*Large Language Models as Optimizers*](https://arxiv.org/abs/2309.03409)
* [*Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models*](https://arxiv.org/abs/2310.06117)
* [*Large Language Models can Learn Rules*](https://arxiv.org/abs/2310.07064)

Even [more XoT papers](https://github.com/Timothyxxx/Chain-of-ThoughtsPapers) and a [*A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future*](https://arxiv.org/abs/2309.15402)