# In-Context Retrieval-Augmented Language Models

This week's paper is the third in the a series on Retrieval Augmented LLMs. [*In-Context Retrieval-Augmented Language Models*](https://arxiv.org/abs/2302.00083) finetunes a retriever for use with a frozen language model.

[Evaluation Code](https://github.com/AI21Labs/in-context-ralm)

Further Reading:
- [*REPLUG: Retrieval-Augmented Black-Box Language Models*](https://arxiv.org/abs/2301.12652)
- [*Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In*](https://arxiv.org/abs/2305.17331)
- [*Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model*](https://arxiv.org/abs/2212.09146)
- [*Query Rewriting for Retrieval-Augmented Large Language Models*](https://arxiv.org/abs/2305.14283)
- [*Active Retrieval Augmented Generation*](https://arxiv.org/abs/2305.06983)