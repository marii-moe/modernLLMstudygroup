# Constitutional AI: Harmlessness from AI Feedback

[*Constitutional AI: Harmlessness from AI Feedback*](https://arxiv.org/abs/2212.08073), one of the first RLAIF papers from Anthropic.

Further Reading:
- [*RAIN: Your Language Models Can Align Themselves without Finetuning*](https://arxiv.org/abs/2309.07124)
- [*RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback*](https://arxiv.org/abs/2309.00267)
- [*Self-Rewarding Language Models*](https://arxiv.org/abs/2401.10020)
- [*Suppressing Pink Elephants with Direct Principle Feedback*](https://arxiv.org/abs/2402.07896)
- [*Reinforcement Learning from Reflective Feedback (RLRF): Aligning and Improving LLMs via Fine-Grained Self-Reflection*](https://arxiv.org/abs/2403.14238)

- [Claudeâ€™s Constitution](https://www.anthropic.com/news/claudes-constitution)